{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "inclusive-friday",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjahns/anaconda3/envs/py39/lib/python3.9/site-packages/FRB-0.1.dev0-py3.9.egg/frb/halos/hmf.py:51: UserWarning: hmf_emulator not imported.  Hope you are not intending to use the hmf.py module..\n",
      "  warnings.warn(\"hmf_emulator not imported.  Hope you are not intending to use the hmf.py module..\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "from scipy.stats import lognorm\n",
    "from scipy.interpolate import interp1d\n",
    "from frb.dm.igm import average_DM\n",
    "from frb.dm import igm\n",
    "from frb.dm import cosmic\n",
    "from frb.dm import mcmc\n",
    "from frb import defs\n",
    "from astropy.cosmology import Planck18_arXiv_v2 as cosmo\n",
    "\n",
    "from mockFRBhosts import draw_galaxies, observed_bands, draw_Delta\n",
    "from mockFRBhosts.mcmc_simulations import do_mcmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f8eb9b6-82ea-4f68-8831-69bc068d8bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define where to save the posteriors.\n",
    "outdir = '../Posteriors/'\n",
    "\n",
    "if not os.path.isdir(outdir):\n",
    "    os.makedirs(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c5c934d-703d-4862-80b8-0a779c9df521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Simulated_FRBs/askap-craco_sfr.pickle',\n",
       " '../Simulated_FRBs/askap-craco_smd.pickle',\n",
       " '../Simulated_FRBs/askap-craco_vol_co.pickle',\n",
       " '../Simulated_FRBs/askap-incoh_sfr.pickle',\n",
       " '../Simulated_FRBs/askap-incoh_smd.pickle',\n",
       " '../Simulated_FRBs/askap-incoh_vol_co.pickle',\n",
       " '../Simulated_FRBs/chime-frb_sfr.pickle',\n",
       " '../Simulated_FRBs/chime-frb_smd.pickle',\n",
       " '../Simulated_FRBs/chime-frb_vol_co.pickle',\n",
       " '../Simulated_FRBs/ska1-mid_sfr.pickle',\n",
       " '../Simulated_FRBs/ska1-mid_smd.pickle',\n",
       " '../Simulated_FRBs/ska1-mid_vol_co.pickle']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load FRBs from the pickle files.\n",
    "pickles = sorted(glob('../Simulated_FRBs/*.pickle'))\n",
    "\n",
    "survey_models, z_models = [], []\n",
    "for file in pickles:\n",
    "    # Extract models from file names.\n",
    "    params = os.path.basename(file)\n",
    "    params = os.path.splitext(params)[0]\n",
    "    params = params.split('_', 1)\n",
    "    survey_models.append(params[0])\n",
    "    z_models.append(params[1])\n",
    "\n",
    "# Check files\n",
    "pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13579bd2-387b-4902-b683-e1b5fa54bcdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Simulated_FRBs/askap-craco_sfr.pickle\n",
      "../Simulated_FRBs/askap-craco_sfr.pickle\n",
      "1028 FRBs in file, using only first 1000\n"
     ]
    }
   ],
   "source": [
    "# Number of FRBs that should be used througout\n",
    "n_frbs = 1000\n",
    "\n",
    "# Pick an FRB survey and redshift distribution\n",
    "chosen = pickles[0]\n",
    "radio_survey = survey_models[0]\n",
    "print(chosen)\n",
    "\n",
    "# Weight galaxy choice depending on file name\n",
    "if os.path.splitext(chosen)[0][-3:] == 'sfr':  # last thre letters before extension\n",
    "    weights = 'mstardot'\n",
    "else:\n",
    "    weights = 'mstars_total'\n",
    "\n",
    "frbs = np.load(chosen, allow_pickle=True)\n",
    "print(frbs.shape[0], \"FRBs in file, using only first\", n_frbs)\n",
    "frbs = frbs.iloc[:n_frbs].copy()\n",
    "\n",
    "galaxies, snapnum = draw_galaxies(frbs['z'], weights=weights, seed=42)\n",
    "\n",
    "# Order FRBs such that they correspond to galaxies at the same positions.\n",
    "frbs.loc[:, 'snapnum'] = snapnum\n",
    "frbs.sort_values('snapnum', ascending=True, inplace=True)\n",
    "\n",
    "n_bands_obs_SDSS, n_bands_obs_LSST, n_bands_obs_Euclid, n_bands_obs_DES = observed_bands(frbs, galaxies)\n",
    "\n",
    "frbs['n_bands_SDSS'] = n_bands_obs_SDSS.to_numpy()\n",
    "frbs['n_bands_LSST'] = n_bands_obs_LSST.to_numpy()\n",
    "frbs['n_bands_Euclid'] = n_bands_obs_Euclid.to_numpy()\n",
    "frbs['n_bands_DES'] = n_bands_obs_DES.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b826eb20-7372-47d4-8c28-523320afbf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give parameter values from which to simulate the DM. Obh70 is not used at the moment, would have to give it to averag_DM.\n",
    "Obh70, F, mu, lognorm_s = cosmo.Ob0*cosmo.H0.value/70, .2, 100, 1\n",
    "\n",
    "# Calculate the average DM up to the highest redshift, interpolate to avoid using this slow function again.\n",
    "# (For every neval an integral is done in frb.dm.igm.avg_rhoISM when cosmo.age(z) is called.)\n",
    "DM_cum, zeval = average_DM(frbs['z'].max(), cosmo=defs.frb_cosmo, cumul=True)\n",
    "avrg_DM = interp1d(zeval, DM_cum, assume_sorted=True)\n",
    "\n",
    "# Draw a DM_IGM from it's PDF. Multiply by <DM_cosmic> to get a DM.\n",
    "rng = np.random.default_rng(seed=42)\n",
    "delta = [float(draw_Delta(z, f=F, n_samples=1, rng=rng)) for z in frbs['z']]\n",
    "dm_cosmic = np.array(delta) * avrg_DM(frbs['z'])\n",
    "\n",
    "# Draw a DM_host from the parameters that Macquart2020 gives.\n",
    "dm_host = lognorm.rvs(lognorm_s, scale=mu, size=len(frbs['z']), random_state=rng)\n",
    "\n",
    "frbs['DM'] = dm_host/(1+frbs['z']) + dm_cosmic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4e8f4f3-fe20-42dc-87e5-ce423cc11dee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "survey = 'SDSS'\n",
    "n_bands_obs = frbs['n_bands_' + survey]\n",
    "n_bands = n_bands_obs.max()\n",
    "\n",
    "# Limit to FRBs with host in all bands and shuffle them.\n",
    "frbs_w_host = frbs[n_bands_obs.to_numpy() == n_bands]\n",
    "rng = np.random.default_rng(seed=42)\n",
    "frbs_w_host = frbs_w_host.sample(frac=1, ignore_index=True, random_state=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8cf904e-644b-4853-a7d6-20f51c5f0afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274\n"
     ]
    }
   ],
   "source": [
    "draws = 150\n",
    "cores = 20\n",
    "\n",
    "frb_set = frbs_w_host\n",
    "\n",
    "n_frbs = len(frb_set)\n",
    "print(n_frbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0218da9a-cc27-4bae-bbab-91d9a9ffbaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Only 150 samples in chain.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Initializing NUTS failed. Falling back to elementwise auto-assignment.\n",
      "Multiprocess sampling (20 chains in 20 jobs)\n",
      "CompoundStep\n",
      ">Slice: [lognorm_s]\n",
      ">Slice: [mu]\n",
      ">Slice: [F]\n",
      ">Slice: [Obh70]\n",
      "/home/jjahns/anaconda3/envs/py39/lib/python3.9/site-packages/FRB-0.1.dev0-py3.9.egg/frb/dm/mcmc.py:285: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/home/jjahns/anaconda3/envs/py39/lib/python3.9/site-packages/FRB-0.1.dev0-py3.9.egg/frb/dm/mcmc.py:285: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/home/jjahns/anaconda3/envs/py39/lib/python3.9/site-packages/FRB-0.1.dev0-py3.9.egg/frb/dm/mcmc.py:285: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/home/jjahns/anaconda3/envs/py39/lib/python3.9/site-packages/FRB-0.1.dev0-py3.9.egg/frb/dm/mcmc.py:285: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/home/jjahns/anaconda3/envs/py39/lib/python3.9/site-packages/FRB-0.1.dev0-py3.9.egg/frb/dm/mcmc.py:285: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/home/jjahns/anaconda3/envs/py39/lib/python3.9/site-packages/FRB-0.1.dev0-py3.9.egg/frb/dm/mcmc.py:285: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/home/jjahns/anaconda3/envs/py39/lib/python3.9/site-packages/FRB-0.1.dev0-py3.9.egg/frb/dm/mcmc.py:285: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/home/jjahns/anaconda3/envs/py39/lib/python3.9/site-packages/FRB-0.1.dev0-py3.9.egg/frb/dm/mcmc.py:285: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/home/jjahns/anaconda3/envs/py39/lib/python3.9/site-packages/FRB-0.1.dev0-py3.9.egg/frb/dm/mcmc.py:285: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/home/jjahns/anaconda3/envs/py39/lib/python3.9/site-packages/FRB-0.1.dev0-py3.9.egg/frb/dm/mcmc.py:285: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/home/jjahns/anaconda3/envs/py39/lib/python3.9/site-packages/FRB-0.1.dev0-py3.9.egg/frb/dm/mcmc.py:285: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/home/jjahns/anaconda3/envs/py39/lib/python3.9/site-packages/FRB-0.1.dev0-py3.9.egg/frb/dm/mcmc.py:285: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n"
     ]
    }
   ],
   "source": [
    "post_path = os.path.join(outdir, f\"{radio_survey}_{survey}_{n_frbs}_zs_{cores}x{draws}_draws.nc\")\n",
    "if not os.path.isfile(post_path):\n",
    "    frb_set = frbs_w_host.iloc[:n_frbs]\n",
    "\n",
    "    idata = do_mcmc(frb_set['z'], frb_set['DM'], draws=draws, cores=cores)\n",
    "    idata.to_netcdf(post_path)\n",
    "\n",
    "else:\n",
    "    print(\"Already existing, skip.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f143d29f-7acd-4300-a3f9-d8b7d86612d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will save to Posteriors/askap-craco_random_sample_of_524_zs_run_0_20x1500_draws.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Initializing NUTS failed. Falling back to elementwise auto-assignment.\n",
      "Multiprocess sampling (20 chains in 20 jobs)\n",
      "CompoundStep\n",
      ">Slice: [lognorm_s]\n",
      ">Slice: [mu]\n",
      ">Slice: [F]\n",
      ">Slice: [Obh70]\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "Sampling 20 chains for 300 tune and 1_500 draw iterations (6_000 + 30_000 draws total) took 3673 seconds.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will save to Posteriors/askap-craco_random_sample_of_524_zs_run_1_20x1500_draws.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Initializing NUTS failed. Falling back to elementwise auto-assignment.\n",
      "Multiprocess sampling (20 chains in 20 jobs)\n",
      "CompoundStep\n",
      ">Slice: [lognorm_s]\n",
      ">Slice: [mu]\n",
      ">Slice: [F]\n",
      ">Slice: [Obh70]\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "Sampling 20 chains for 300 tune and 1_500 draw iterations (6_000 + 30_000 draws total) took 3912 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will save to Posteriors/askap-craco_random_sample_of_524_zs_run_2_20x1500_draws.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Initializing NUTS failed. Falling back to elementwise auto-assignment.\n",
      "Multiprocess sampling (20 chains in 20 jobs)\n",
      "CompoundStep\n",
      ">Slice: [lognorm_s]\n",
      ">Slice: [mu]\n",
      ">Slice: [F]\n",
      ">Slice: [Obh70]\n",
      "Sampling 20 chains for 300 tune and 1_500 draw iterations (6_000 + 30_000 draws total) took 3743 seconds.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n"
     ]
    }
   ],
   "source": [
    "# Creat random samples from the FRB population to compare with.\n",
    "rndm_sample1 = frbs.sample(n=n_frbs, ignore_index=True, random_state=rng)\n",
    "rndm_sample2 = frbs.sample(n=n_frbs, ignore_index=True, random_state=rng)\n",
    "rndm_sample3 = frbs.sample(n=n_frbs, ignore_index=True, random_state=rng)\n",
    "\n",
    "for frb_set in [rndm_sample1, rndm_sample2, rndm_sample3]:\n",
    "    i = 0\n",
    "    post_path = os.path.join(outdir, f\"{radio_survey}_{survey}_random_sample_of_{len(frb_set)}_zs_run_{i}_{cores}x{draws}_draws.nc\")\n",
    "    # Don't overwrite existing files.\n",
    "    while os.path.isfile(post_path):\n",
    "        i += 1\n",
    "        post_path = os.path.join(outdir, f\"{radio_survey}_{survey}_random_sample_of_{len(frb_set)}_zs_run_{i}_{cores}x{draws}_draws.nc\")\n",
    "        \n",
    "    print(f\"Will save to {post_path}\")\n",
    "\n",
    "    frb_set = frbs_w_host.iloc[:n_frbs]\n",
    "\n",
    "    idata = do_mcmc(frb_set['z'], frb_set['DM'], draws=draws, cores=cores)\n",
    "    idata.to_netcdf(post_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08b02121-c675-480c-b92a-fefdcec71567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10,\n",
       " 11,\n",
       " 13,\n",
       " 15,\n",
       " 17,\n",
       " 19,\n",
       " 22,\n",
       " 26,\n",
       " 29,\n",
       " 34,\n",
       " 39,\n",
       " 44,\n",
       " 51,\n",
       " 58,\n",
       " 67,\n",
       " 77,\n",
       " 88,\n",
       " 101,\n",
       " 116,\n",
       " 133,\n",
       " 153,\n",
       " 175,\n",
       " 201,\n",
       " 230,\n",
       " 264,\n",
       " 303,\n",
       " 347,\n",
       " 398,\n",
       " 457,\n",
       " 523]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sorted(list(set(np.logspace(1, np.log10(len(frbs_w_host)), 30, dtype=int)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "171fbbf0-64c5-45c9-a778-779fd008fd30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Initializing NUTS failed. Falling back to elementwise auto-assignment.\n",
      "Multiprocess sampling (20 chains in 20 jobs)\n",
      "CompoundStep\n",
      ">Slice: [lognorm_s]\n",
      ">Slice: [mu]\n",
      ">Slice: [F]\n",
      ">Slice: [Obh70]\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "Sampling 20 chains for 300 tune and 1_500 draw iterations (6_000 + 30_000 draws total) took 148 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Initializing NUTS failed. Falling back to elementwise auto-assignment.\n",
      "Multiprocess sampling (20 chains in 20 jobs)\n",
      "CompoundStep\n",
      ">Slice: [lognorm_s]\n",
      ">Slice: [mu]\n",
      ">Slice: [F]\n",
      ">Slice: [Obh70]\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "/tmp/ipykernel_121866/1552272071.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  log_like = np.sum(np.log(likelihoods*normalizations/avgDM))\n",
      "Sampling 20 chains for 300 tune and 1_500 draw iterations (6_000 + 30_000 draws total) took 178 seconds.\n"
     ]
    }
   ],
   "source": [
    "draws = 150\n",
    "cores = 20\n",
    "\n",
    "for n_frbs in sorted(list(set(np.logspace(1, np.log10(len(frbs_w_host)), 30, dtype=int)))): # [5,7]: #\n",
    "    print(n_frbs)\n",
    "\n",
    "    post_path = os.path.join(outdir, f\"{radio_survey}_{survey}_{n_frbs}_zs_{cores}x{draws}_draws.nc\")\n",
    "    if os.path.isfile(post_path):\n",
    "        continue\n",
    "    \n",
    "    frb_set = frbs_w_host.iloc[:n_frbs]\n",
    "\n",
    "    idata = do_mcmc(frb_set['z'], frb_set['DM'], draws=draws, cores=cores)\n",
    "    idata.to_netcdf(post_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
